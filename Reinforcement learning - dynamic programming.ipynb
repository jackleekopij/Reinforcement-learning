{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning - dynamic programming\n",
    "\n",
    "At the core of reinforcement learning is the derivation of an optimal policy; a function which calculates actions to be executed from a state. The reinforcement learning problem is suited to solving a framework framework of problems termed Markov Decision Processes (MDPs). These processes are characterised by five key parameters, S (state), A (action), P (transition matrix), R (reward) and \\gamma (discount factor). If all five parameters are explicitly known, dynamic programming can be applied to MDPs to solve *(value) prediction* and *(optimal) control*. \n",
    "\n",
    "Dynamic programming provides a methodology to solve complex problems by breaking large/complex problems into smaller/more simple subproblems, solving subproblems and finally using subproblem solutions to construct solutions to the overall problem. Two important properties of dynamic programming: \n",
    "\n",
    "    1. Optimal substructure\n",
    "    2. Overlapping subproblems\n",
    "    \n",
    "    1. Optimal substructure\n",
    "    The idea of optimal substructure is premised on the idea complex problems can be decomposed into subproblems, calculate the optimal value for each subproblem then combine to form the overall optimal solution. \n",
    "    \n",
    "    2. Overlapping subproblems\n",
    "    Second, dynamic programming uses overlapping subproblems to cache solutions to previously calculated subproblems, store the output and reuse in calculations when the subproblems reoccur. \n",
    "    \n",
    "    \n",
    "Problems of the above form can be solved in both a prediction and control setting. Prediction solutions calculates the total value achievable from a state under a specific policy whereas control determines the action/decision that should be made in each state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy evaluation - prediction\n",
    "Policy evaluation aims to solve the problem - \"if I follow a particular policy \\pi how 'good' is it to be in a particular state\". An MDP and policy are given the policy is then evaluated as to how optimal it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import numpy as np\n",
    "\n",
    "CANVAS_HEIGHT_WIDTH = 600\n",
    "GRID_DIM = 5\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "DISCOUNT_FACTOR = 1.0\n",
    "REWARD = -1\n",
    "\n",
    "line_distance = CANVAS_HEIGHT_WIDTH/GRID_DIM\n",
    "label_offset = line_distance/2\n",
    "\n",
    "\n",
    "#### Define policy\n",
    "trans_prob = {\"UP\":0.25, \"DOWN\":0.25, \"LEFT\":0.25, \"RIGHT\":0.25}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
